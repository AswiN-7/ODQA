{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.10k/1.10k [00:00<00:00, 1.12MB/s]\n",
      "Downloading: 100%|██████████| 590k/590k [00:00<00:00, 666kB/s] \n",
      "Downloading: 100%|██████████| 331k/331k [00:00<00:00, 512kB/s] \n",
      "Downloading: 100%|██████████| 772/772 [00:00<00:00, 750kB/s]\n",
      "Downloading: 100%|██████████| 636/636 [00:00<00:00, 616kB/s]\n",
      "Downloading: 100%|██████████| 256M/256M [00:25<00:00, 10.7MB/s]   \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AswiN037/tamil-Roberta-small\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"AswiN037/tamil-Roberta-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.16797690093517303,\n",
       "  'token': 4,\n",
       "  'token_str': '<mask>',\n",
       "  'sequence': 'சிரிப்பு இல்லாத சிறகு இல்லாத பறவைக்கு சமம்.'},\n",
       " {'score': 0.0002627014182507992,\n",
       "  'token': 6336,\n",
       "  'token_str': ' link',\n",
       "  'sequence': 'சிரிப்பு இல்லாத link சிறகு இல்லாத பறவைக்கு சமம்.'},\n",
       " {'score': 0.00021842599380761385,\n",
       "  'token': 20152,\n",
       "  'token_str': 'Search',\n",
       "  'sequence': 'சிரிப்பு இல்லாதSearch சிறகு இல்லாத பறவைக்கு சமம்.'},\n",
       " {'score': 0.00021697136980947107,\n",
       "  'token': 10646,\n",
       "  'token_str': ' youth',\n",
       "  'sequence': 'சிரிப்பு இல்லாத youth சிறகு இல்லாத பறவைக்கு சமம்.'},\n",
       " {'score': 0.00020036357454955578,\n",
       "  'token': 6192,\n",
       "  'token_str': 'ரகவ',\n",
       "  'sequence': 'சிரிப்பு இல்லாதரகவ சிறகு இல்லாத பறவைக்கு சமம்.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"சிரிப்பு இல்லாத வாழ்க்கை சிறகு இல்லாத பறவைக்கு சமம்.\"]\n",
    "masked_text = [f\"சிரிப்பு இல்லாத {fill.tokenizer.mask_token} சிறகு இல்லாத பறவைக்கு சமம்.\"]\n",
    "fill(masked_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1638135015964508,\n",
       "  'token': 4,\n",
       "  'token_str': '<mask>',\n",
       "  'sequence': 'நான் கணினிப் பொறியியல்'},\n",
       " {'score': 0.0002775640459731221,\n",
       "  'token': 462,\n",
       "  'token_str': ' அதன',\n",
       "  'sequence': 'நான் கணினிப் பொறியியல் அதன'},\n",
       " {'score': 0.00020209793001413345,\n",
       "  'token': 2926,\n",
       "  'token_str': 'ளனம',\n",
       "  'sequence': 'நான் கணினிப் பொறியியல்ளனம'},\n",
       " {'score': 0.0002020162355620414,\n",
       "  'token': 7018,\n",
       "  'token_str': 'public',\n",
       "  'sequence': 'நான் கணினிப் பொறியியல்public'},\n",
       " {'score': 0.00019224980496801436,\n",
       "  'token': 6336,\n",
       "  'token_str': ' link',\n",
       "  'sequence': 'நான் கணினிப் பொறியியல் link'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"நான் கணினிப் பொறியியல் படிக்கிறேன்\"\n",
    "masked_text = f\"நான் கணினிப் பொறியியல் {fill.tokenizer.mask_token}\"\n",
    "fill(masked_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = r'../dataset/tamilqa.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fp, \"r\") as read_file:\n",
    "  qa = pd.read_json(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa = qa.reset_index()  # make sure indexes pair with number of rows\n",
    "\n",
    "# dataset = [{'context' : row['context'], \n",
    "#             'id' : row['qas'][0]['id'], \n",
    "#             'question':  row['qas'][0]['question'], \n",
    "#             'answers':  row['qas'][0]['answers']} for i, row in tqdm(qa.iterrows())]\n",
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                           0\n",
       "context         ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...\n",
       "question                     மனித உடலில் எத்தனை எலும்புகள் உள்ளன?\n",
       "answer_text                                                   206\n",
       "answer_start                                                   53\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'context', 'question', 'answer_text', 'answer_start'],\n",
       "    num_rows: 367\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dataset[0]['question']\n",
    "query\n",
    "\n",
    "docs = [ ]\n",
    "count = 0\n",
    "for item in dataset:\n",
    "    if count < 10:\n",
    "        docs.append(item['context'])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take average of all tokens\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.logits #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "#Encode text\n",
    "def encode(texts):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform pooling\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "#Encode query and docs\n",
    "query_emb = encode(query)\n",
    "doc_emb = encode(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def retrieve_similar_contexts(context_embeddings, question_embedding):\n",
    "  similarity_score = []\n",
    "  for em in tqdm(context_embeddings):\n",
    "    cos = torch.nn.CosineSimilarity(dim=0)\n",
    "    output = cos(question_embedding, em)\n",
    "    similarity_score.append((len(similarity_score), output))\n",
    "  return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = retrieve_similar_contexts(doc_emb, query_emb[0])\n",
    "sim_scores"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "183bbf6827d058c2a2fb0f4acdc0420849dda2b4380af0e437e38c64d798d8b7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
