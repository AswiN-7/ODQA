{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')\n",
    "model = AutoModel.from_pretrained('ai4bharat/indic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take average of all tokens\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "#Encode text\n",
    "def encode(texts):\n",
    "    # Tokenize sentences\n",
    "    doc_stride = 128\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512, stride=doc_stride, return_overflowing_tokens = True)\n",
    "    encoded_input.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform pooling\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "conn = pymysql.connect(host='localhost', user='aswin', port=3306, password='Mysql@123', database='ODQA',local_infile=True)\n",
    "cursor = conn.cursor()\n",
    "print(\"odqa\")\n",
    "# print(\"this is imp\")\n",
    "TABLE_NAME = 'QA_DATASET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_table():\n",
    "    #Deleting previouslny stored table for clean run\n",
    "    drop_table = \"DROP TABLE IF EXISTS \" + TABLE_NAME + \";\"\n",
    "    cursor.execute(drop_table)\n",
    "    try:\n",
    "        # sql = \"CREATE TABLE if not exists \" + TABLE_NAME + \" (id TEXT, context TEXT);\"\n",
    "        sql = f\"\"\"\n",
    "                CREATE TABLE if not exists {TABLE_NAME} (\n",
    "                    id int(10) NOT NULL AUTO_INCREMENT,\n",
    "                    question TEXT COLLATE utf8_bin NOT NULL,\n",
    "                    context MEDIUMTEXT COLLATE utf8_bin NOT NULL,\n",
    "                    answer  TEXT COLLATE utf8_bin NOT NULL,\n",
    "                    answer_start int(5) NOT NULL,\n",
    "                    PRIMARY KEY (id)\n",
    "                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\n",
    "                AUTO_INCREMENT=1 ;\"\"\"\n",
    "        cursor.execute(sql)\n",
    "        print(f\"{TABLE_NAME} table successfully!\")\n",
    "    except Exception as e:\n",
    "        print(\"can't create a MySQL table: \", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query):\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        return rows\n",
    "    except Exception as e:\n",
    "        print(\"can't create a MySQL table: \", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(dataset):\n",
    "    \"\"\"\n",
    "    context should be array of contexts\n",
    "    [con1, con2, ...]\n",
    "    \"\"\"\n",
    "    # q = \"select count(id) from context\"\n",
    "    # res = execute_query(q)\n",
    "    # current_size = res[0][0]\n",
    "    # next = current_size+1\n",
    "    for data in dataset:\n",
    "        sql = \"INSERT INTO QA_DATASET (question, context, answer, answer_start) VALUES (%s, %s, %s, %s)\"\n",
    "        cursor.execute(sql, (data[\"question\"], data[\"context\"], data[\"answer\"], data[\"answer_start\"]))\n",
    "        # next+=1 \n",
    "    conn.commit()\n",
    "\n",
    "def extract_context(id):\n",
    "    q = f\"select context from QA_DATASET where id = {id}\"\n",
    "    res = execute_query(q)\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILVUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['sop_classifier.classifier.bias', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "connections.connect()\n",
    "import odqa_mysql as odqa_mysql\n",
    "import odqa_encoder as odqa_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "TABLE_NAME = 'question_answering'\n",
    "collection = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting previouslny stored table for clean run\n",
    "def create_mqa():\n",
    "    if utility.has_collection(TABLE_NAME):\n",
    "        collection = Collection(name=TABLE_NAME)\n",
    "        collection.drop()\n",
    "\n",
    "    field1 = FieldSchema(name=\"ind\", dtype=DataType.INT64, descrition=\"int64\", is_primary=True)\n",
    "    field2 = FieldSchema(name=\"id\", dtype=DataType.INT64, descrition=\"int64\", is_primary=False)\n",
    "    field3 = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, descrition=\"float vector\",dim=768, is_primary=False)\n",
    "    schema = CollectionSchema(fields=[field1, field2, field3], description=\"collection description\")\n",
    "    collection = Collection(name=TABLE_NAME, schema=schema)\n",
    "    \n",
    "    default_index = {\"index_type\": \"IVF_FLAT\", \"metric_type\": 'IP', \"params\": {\"nlist\": 200}}\n",
    "    collection.create_index(field_name=\"embedding\", index_params=default_index)\n",
    "\n",
    "if utility.has_collection(TABLE_NAME):\n",
    "    collection = Collection(name=TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}}\n",
    "\n",
    "def find_similar(emb):\n",
    "    collection.load()\n",
    "    return collection.search(\n",
    "\tdata=emb, \n",
    "\tanns_field=\"embedding\", \n",
    "\tparam=search_params, \n",
    "\tlimit=10, \n",
    "\texpr=None,\n",
    "\tconsistency_level=\"Strong\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def push_context_to_milvus():\n",
    "    print(\"\\n\\n\")\n",
    "    db_fp = r\"database_handler.json\"\n",
    "    file = open(db_fp)\n",
    "    database_handler = json.loads(file.read())\n",
    "    file.close()\n",
    "\n",
    "    start= database_handler['milvus_rows']\n",
    "    end= start+database_handler[\"batch\"]\n",
    "    index = database_handler['milvus_rows']\n",
    "    \n",
    "    query = f\"select * from context where id between {start} and {end} ;\"\n",
    "    res = odqa_mysql.execute_query(query)\n",
    "\n",
    "    for id, context in tqdm(res):\n",
    "        emb = odqa_encoder.encode(context)\n",
    "        indexs = []\n",
    "        ids = []\n",
    "        for i in range(len(emb)):\n",
    "            indexs.append(index)\n",
    "            index+=1  \n",
    "            ids.append(id)\n",
    "        # print(emb, indexs, ids)\n",
    "        collection.insert([indexs, ids, emb])\n",
    "           \n",
    "    database_handler['milvus_rows'] = end\n",
    "    database_handler['milvus_index'] = index\n",
    "\n",
    "    file = open(db_fp,\"w\")\n",
    "    json.dump(database_handler, file)\n",
    "    file.close()\n",
    "    \n",
    "    mysql_size = odqa_mysql.execute_query(\"select count(*) from QA_DATASET\")[0][0]\n",
    "    return f\"mysql : {mysql_size}\\nmilvus : {collection.num_entities}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mqa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mysql : 368\\nmilvus : 229'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push_context_to_milvus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query():\n",
    "    collection.load()\n",
    "    return collection.query(\n",
    "\tanns_field=\"embedding\", \n",
    "\tparam=search_params, \n",
    "\tlimit=10, \n",
    "\texpr=\"id == 6\",\n",
    "\tconsistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ind': 36},\n",
       " {'ind': 37},\n",
       " {'ind': 38},\n",
       " {'ind': 41},\n",
       " {'ind': 33},\n",
       " {'ind': 34},\n",
       " {'ind': 35},\n",
       " {'ind': 39},\n",
       " {'ind': 40}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  pipeline\n",
    "\n",
    "# model_name = \"deepset/xlm-roberta-large-squad2\"\n",
    "model_name = \"AswiN037/xlm-roberta-squad-tamil\"\n",
    "\n",
    "answer_extract = pipeline('question-answering', model=model_name, tokenizer=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install absl-py\n",
    "# !pip install rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [['206', ' 206'],\n",
    " ['காசுமீரில்', ' காசுமீரில்'],\n",
    " ['சர் அலெக்ஸாண்டர் ஃபிளெமிங்', ' அலெக் ஸாண்டர் ஃப்பௌமிங்.'],\n",
    " ['தாலாட்டு', '\\n(ஆயர்பாடி…)'],\n",
    " ['சூரியனும்', ' சூரியன்'],\n",
    " ['IBM', ' IBM'],\n",
    " ['அலெக்ஸாண்டர் கிரகாம் பெல்', ' பெல்'],\n",
    " ['1914ம்', ' (1914'],\n",
    " ['அக்டோபர் 12, 1993', ' அக்டோபர் 12, 1993[1]'],\n",
    " ['27', ' 27'],\n",
    " ['உருகுவே', ' பிரேசில்'],\n",
    " ['பிரான்ஸ்', ' பிரான்ஸ்'],\n",
    " ['30,368,609', '\\n(km²)'],\n",
    " ['185 மீட்டர்', ' 185 மீட்டர்'],\n",
    " ['கி.பி.1510', '\\nகி.பி.1510-ம்'],\n",
    " ['கி.மு. ஐந்தாம் நூற்றாண்டில்', ' (கி.மு 470/469'],\n",
    " ['60 நொடிகள்', ' 60'],\n",
    " ['பசுபிக்', ' பசுபிக்'],\n",
    " ['லிஸ்பன்', ' லிஸ்பன்'],\n",
    " ['உடல் திசு ஆய்வு', ' (Men Get Breast Cancer'],\n",
    " ['சசி', ' சசி'],\n",
    " ['1,376  கிலோ மீட்டர்', ' 1370 கிமீ'],\n",
    " ['1000', ' 1025நீர்  1000ஈத்தைல்'],\n",
    " ['மூங்கில்', ' மூங்கிலால்'],\n",
    " ['புளோரிடாவில்', ' புளோரிடாவில்'],\n",
    " ['208', ' 206'],\n",
    " ['இந்தியத் திரைப்பட இசைப் பாடகர்', ' பின்னணிப்பாடகர்'],\n",
    " ['5488', ' 5488'],\n",
    " ['சனவரி 28, 1892', ' 1995'],\n",
    " ['அலெக்ஸாண்டர்-எட்மண்ட பெக்கெரெலின்', ' ஆர்க்கிமிடீஸ்'],\n",
    " ['அகுவாபா', ' அகுவாபா'],\n",
    " ['பிரிட்டனில்', ' ஸ்பெயினில்,'],\n",
    " ['புதன்', ' (Mercury)'],\n",
    " ['நெமடோடா', '\\nஎக்டிசாசோவாக்கள்'],\n",
    " ['26 மே 2001', ' 26 மே 2001'],\n",
    " ['8 லட்சத்துக்கு', ' 8 லட்சத்துக்கு மேற்பட்டவை'],\n",
    " ['அ. இர. ரகுமான்', ' நியமிக்கப்பட்டார்.[5]'],\n",
    " ['தொற்று', '\\nதொற்று'],\n",
    " ['தமிழ்', ' தமிழ்'],\n",
    " ['Hibiscus rosa-sinensis', ' செவ்வரத்தை'],\n",
    " ['கரிகாலன்', ' கரிகாலன்'],\n",
    " ['சுவீடனில்', ' சுவீடனில்'],\n",
    " ['மேரிகியூரி மற்றும் பியரிகியூரி தம்பதியரால்',\n",
    "  ' மேரிகியூரி மற்றும் பியரிகியூரி'],\n",
    " ['10,911', ' 4,694 மீட்டர்.'],\n",
    " ['பசிபிக் பெருங்கடலாகும்', ' அத்திலாந்திக் பெருங்கடல்'],\n",
    " ['புதன்', ' வாகும்.'],\n",
    " ['செவுள்கள், நுரையீரலால்', ' (நுரையீரல்'],\n",
    " ['1,568.7 square kilometres', ' 1,568.7 square kilometres'],\n",
    " ['தோக்கியோ', ' தோக்கியோ'],\n",
    " ['1000', ' 1000'],\n",
    " ['விஷம்', ' விஷம் கொடுத்துக்'],\n",
    " ['மெசொப்பொத்தேமியர்கள்', ' எகிப்தியர்கள்'],\n",
    " ['பிடி', ' பிடி'],\n",
    " ['ஈராக்', ' Mesopotamia.'],\n",
    " ['சனவரி 26ஆம்', ' குடியரசு நாள் அன்று'],\n",
    " ['ஆறாம் முகம்மது', '\\nமுதலாம் சுலைமானின்'],\n",
    " ['செவ்வாய்', ' செவ்வாயின்'],\n",
    " ['1901', ' 1901'],\n",
    " ['29', ' 14'],\n",
    " ['வெளிப்பரப்பு அடர்த்தியான சாம்பல் நிறத்திலும், உள்நிறை மஞ்சள், வெள்ளை',\n",
    "  ' சாம்பல்'],\n",
    " ['1623', ' 27 அக்டோபர் 1605),[3][4]'],\n",
    " ['பைக்கால்', ' பைக்கால்'],\n",
    " ['அவுஸ்திரேலியா', ' ஆஸ்திரேலிய'],\n",
    " ['ஒழுங்கற்ற', ' இரண்டாவது சிறிய'],\n",
    " ['மாட்ரிட்', ' மாட்ரிட்.'],\n",
    " ['என்றிகோ பெர்மியின்', ' என்றிகோ பெர்மியின்'],\n",
    " ['70 ஆண்டுகள்', ' 70 ஆண்டுகள்).'],\n",
    " ['பெங்களூரு', ' பெங்களூரில்'],\n",
    " ['ஆறு', ' ஆறு'],\n",
    " ['ஐந்தில் ஒரு பங்கு', ' ஐந்தில் ஒரு பங்கு'],\n",
    " ['1982', ' 1982ம்'],\n",
    " ['ஆல்ஃபிரட் நோபல்', ' ஆல்ஃபிரட் நோபெல்'],\n",
    " ['தென் அமெரிக்க', ' தென் அமெரிக்க'],\n",
    " ['சாக்ரடீசு', ' பிளேட்டோவும்'],\n",
    " ['பழங்குடி மொழி', ' பழங்குடி மொழி'],\n",
    " ['சர்தார் வல்லப்பாய் படேல்', ' சர்தார் வல்லப்பாய் படேல்'],\n",
    " ['70', ' 70 ஆண்டுகள்).'],\n",
    " ['7870', ' 7870வெள்ளீயம்'],\n",
    " ['ஆர்கெண்ட்டம்', ' ஆர்கெண்ட்டம்'],\n",
    " ['டிசம்பர் 25, 1642', ' (டிசம்பர் 25, 1642'],\n",
    " ['கெய்ரோ', ' கெய்ரோ'],\n",
    " ['எட்டு கோள்களையும், ஐந்து குறுங்கோள்களையும்', ' எட்டு'],\n",
    " ['கொலம்பசு', ' கொலம்பஸ்'],\n",
    " ['2008', ' 1957'],\n",
    " ['350,000', ' (International Code of Nomenclature for Cultivated Plants)'],\n",
    " ['இரண்டு மில்லியன் சதுர கிலோமீட்டர்', '\\n1,972,550 சதுர கிலோமீட்டர்'],\n",
    " ['1935', ' 1935'],\n",
    " ['3', ' 3'],\n",
    " ['ஜான் ஷெப்பர்ட் பேரோன்', ' ஜான் ஷெப்பர்ட் பேரோன்'],\n",
    " ['பிரெஞ்சு', ' பிரெஞ்சு'],\n",
    " ['24', ' 24']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = [res[0][0]]\n",
    "# reference = [res[0][1]]\n",
    "reference = []\n",
    "predictions = []\n",
    "\n",
    "for ref, pre in res:\n",
    "    reference.append(ref)\n",
    "    predictions.append(pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 91)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.16112637362637366, recall=0.16483516483516483, fmeasure=0.1641025641025641), mid=Score(precision=0.24358974358974356, recall=0.25274725274725274, fmeasure=0.2468864468864469), high=Score(precision=0.3461996336996337, recall=0.3626373626373626, fmeasure=0.35239926739926736)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.005494505494505495, recall=0.01098901098901099, fmeasure=0.007326007326007326), mid=Score(precision=0.038461538461538464, recall=0.04395604395604396, fmeasure=0.04029304029304029), high=Score(precision=0.07706043956043944, recall=0.08791208791208792, fmeasure=0.08424908424908424)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.15929487179487184, recall=0.16483516483516483, fmeasure=0.16117216117216115), mid=Score(precision=0.24725274725274726, recall=0.25274725274725274, fmeasure=0.2490842490842491), high=Score(precision=0.32967032967032966, recall=0.34065934065934067, fmeasure=0.33342490842490835)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.15384615384615385, recall=0.16483516483516483, fmeasure=0.15893772893772895), mid=Score(precision=0.24267399267399264, recall=0.25274725274725274, fmeasure=0.2468864468864469), high=Score(precision=0.32783882783882784, recall=0.34065934065934067, fmeasure=0.33261904761904765))}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.compute(predictions=predictions, references=reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
