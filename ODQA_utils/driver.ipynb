{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')\n",
    "model = AutoModel.from_pretrained('ai4bharat/indic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take average of all tokens\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "#Encode text\n",
    "def encode(texts):\n",
    "    # Tokenize sentences\n",
    "    doc_stride = 128\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512, stride=doc_stride, return_overflowing_tokens = True)\n",
    "    encoded_input.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform pooling\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "conn = pymysql.connect(host='localhost', user='aswin', port=3306, password='Mysql@123', database='ODQA',local_infile=True)\n",
    "cursor = conn.cursor()\n",
    "print(\"odqa\")\n",
    "# print(\"this is imp\")\n",
    "TABLE_NAME = 'QA_DATASET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_table():\n",
    "    #Deleting previouslny stored table for clean run\n",
    "    drop_table = \"DROP TABLE IF EXISTS \" + TABLE_NAME + \";\"\n",
    "    cursor.execute(drop_table)\n",
    "    try:\n",
    "        # sql = \"CREATE TABLE if not exists \" + TABLE_NAME + \" (id TEXT, context TEXT);\"\n",
    "        sql = f\"\"\"\n",
    "                CREATE TABLE if not exists {TABLE_NAME} (\n",
    "                    id int(10) NOT NULL AUTO_INCREMENT,\n",
    "                    question TEXT COLLATE utf8_bin NOT NULL,\n",
    "                    context MEDIUMTEXT COLLATE utf8_bin NOT NULL,\n",
    "                    answer  TEXT COLLATE utf8_bin NOT NULL,\n",
    "                    answer_start int(5) NOT NULL,\n",
    "                    PRIMARY KEY (id)\n",
    "                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\n",
    "                AUTO_INCREMENT=1 ;\"\"\"\n",
    "        cursor.execute(sql)\n",
    "        print(f\"{TABLE_NAME} table successfully!\")\n",
    "    except Exception as e:\n",
    "        print(\"can't create a MySQL table: \", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query):\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        return rows\n",
    "    except Exception as e:\n",
    "        print(\"can't create a MySQL table: \", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(dataset):\n",
    "    \"\"\"\n",
    "    context should be array of contexts\n",
    "    [con1, con2, ...]\n",
    "    \"\"\"\n",
    "    # q = \"select count(id) from context\"\n",
    "    # res = execute_query(q)\n",
    "    # current_size = res[0][0]\n",
    "    # next = current_size+1\n",
    "    for data in dataset:\n",
    "        sql = \"INSERT INTO QA_DATASET (question, context, answer, answer_start) VALUES (%s, %s, %s, %s)\"\n",
    "        cursor.execute(sql, (data[\"question\"], data[\"context\"], data[\"answer\"], data[\"answer_start\"]))\n",
    "        # next+=1 \n",
    "    conn.commit()\n",
    "\n",
    "def extract_context(id):\n",
    "    q = f\"select context from QA_DATASET where id = {id}\"\n",
    "    res = execute_query(q)\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILVUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['sop_classifier.classifier.bias', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "connections.connect()\n",
    "import odqa_mysql as odqa_mysql\n",
    "import odqa_encoder as odqa_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "TABLE_NAME = 'question_answering'\n",
    "collection = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting previouslny stored table for clean run\n",
    "def create_mqa():\n",
    "    if utility.has_collection(TABLE_NAME):\n",
    "        collection = Collection(name=TABLE_NAME)\n",
    "        collection.drop()\n",
    "\n",
    "    field1 = FieldSchema(name=\"ind\", dtype=DataType.INT64, descrition=\"int64\", is_primary=True)\n",
    "    field2 = FieldSchema(name=\"id\", dtype=DataType.INT64, descrition=\"int64\", is_primary=False)\n",
    "    field3 = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, descrition=\"float vector\",dim=768, is_primary=False)\n",
    "    schema = CollectionSchema(fields=[field1, field2, field3], description=\"collection description\")\n",
    "    collection = Collection(name=TABLE_NAME, schema=schema)\n",
    "    \n",
    "    default_index = {\"index_type\": \"IVF_FLAT\", \"metric_type\": 'IP', \"params\": {\"nlist\": 200}}\n",
    "    collection.create_index(field_name=\"embedding\", index_params=default_index)\n",
    "\n",
    "if utility.has_collection(TABLE_NAME):\n",
    "    collection = Collection(name=TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}}\n",
    "\n",
    "def find_similar(emb):\n",
    "    collection.load()\n",
    "    return collection.search(\n",
    "\tdata=emb, \n",
    "\tanns_field=\"embedding\", \n",
    "\tparam=search_params, \n",
    "\tlimit=10, \n",
    "\texpr=None,\n",
    "\tconsistency_level=\"Strong\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def push_context_to_milvus():\n",
    "    print(\"\\n\\n\")\n",
    "    db_fp = r\"database_handler.json\"\n",
    "    file = open(db_fp)\n",
    "    database_handler = json.loads(file.read())\n",
    "    file.close()\n",
    "\n",
    "    start= database_handler['milvus_rows']\n",
    "    end= start+database_handler[\"batch\"]\n",
    "    index = database_handler['milvus_rows']\n",
    "    \n",
    "    query = f\"select * from context where id between {start} and {end} ;\"\n",
    "    res = odqa_mysql.execute_query(query)\n",
    "\n",
    "    for id, context in tqdm(res):\n",
    "        emb = odqa_encoder.encode(context)\n",
    "        indexs = []\n",
    "        ids = []\n",
    "        for i in range(len(emb)):\n",
    "            indexs.append(index)\n",
    "            index+=1  \n",
    "            ids.append(id)\n",
    "        # print(emb, indexs, ids)\n",
    "        collection.insert([indexs, ids, emb])\n",
    "           \n",
    "    database_handler['milvus_rows'] = end\n",
    "    database_handler['milvus_index'] = index\n",
    "\n",
    "    file = open(db_fp,\"w\")\n",
    "    json.dump(database_handler, file)\n",
    "    file.close()\n",
    "    \n",
    "    mysql_size = odqa_mysql.execute_query(\"select count(*) from QA_DATASET\")[0][0]\n",
    "    return f\"mysql : {mysql_size}\\nmilvus : {collection.num_entities}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mqa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mysql : 368\\nmilvus : 229'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push_context_to_milvus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query():\n",
    "    collection.load()\n",
    "    return collection.query(\n",
    "\tanns_field=\"embedding\", \n",
    "\tparam=search_params, \n",
    "\tlimit=10, \n",
    "\texpr=\"id == 6\",\n",
    "\tconsistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ind': 36},\n",
       " {'ind': 37},\n",
       " {'ind': 38},\n",
       " {'ind': 41},\n",
       " {'ind': 33},\n",
       " {'ind': 34},\n",
       " {'ind': 35},\n",
       " {'ind': 39},\n",
       " {'ind': 40}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  pipeline\n",
    "\n",
    "# model_name = \"deepset/xlm-roberta-large-squad2\"\n",
    "model_name = \"AswiN037/xlm-roberta-squad-tamil\"\n",
    "\n",
    "answer_extract = pipeline('question-answering', model=model_name, tokenizer=model_name)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
